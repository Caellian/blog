---
title: "Rust Type Metaprogramming - Part 1"
summary: "Theory and practice of proof carrying code in Rust"
next: "2024/rust_metaprogramming_part2"
toot: "111705676105732187"
tags:
  - Rust
  - metaprogramming
  - abstraction
---

## Terminology

**Metaprogramming** is a term used to describe development that involves writing
proof carrying code executed at compile-time by the compiler in order to provide
less verbose type interfaces.

**Proof carrying code** is code that utilizes mechanisms provided by a compiler
to demonstrate and verify its own correctness through type restrictions or
requirements the compiler can understand.

[Associated **type projection**](https://rustc-dev-guide.rust-lang.org/traits/goals-and-clauses.html#trait-ref)
is resolution of a type from relative type path.

**Type path** is a sequence of delimited type identifiers (with `::` in Rust)
whose resolution yields a type which is a child element of the initial type
structure (e.g. `FromStr::Err`). Not to be confused with
[paths in topology](https://proofwiki.org/wiki/Definition:Path_%28Topology%29).

## Context

This article intoduces type metaprogramming with simple type list construction
and mapping. Later articles will delve into other operations that will be
necessary do consume produced type lists.

It will go over type transformations that are necessary in order to provide
end-users with a type safe interface while reducing the area of library
internals they're exposed to.

Rust metaprogramming is generally done with macros, and when people in Rust
community say metaprogramming they usually refer to writing procedural macros.

- Macros do carry proof because code generated by macros will produce compiler
  errors when type requirements aren't met or the produced syntax is invalid.
- Macros however aren't ideal in some scenarios and allow end-users to violate
  semantic API requirements which can in turn cause undefined behavior.

## Prior Art

After writing the inital version of this post I stumbled upon a conference
talk ["Type Theory for the Working Rustacean"](https://www.youtube.com/watch?v=BdXWlQsd7RI)
by [Dan Pittman](https://dpitt.me/), which associates the ideas behind this
post with formal foundations in [type theory](https://en.wikipedia.org/wiki/Type_theory).

Other than that, I've only managed to find posts that describe metaprogramming
via macros in context of Rust:

- ["Understanding and Implementing Rust's Metaprogramming"](https://reintech.io/blog/understanding-implementing-rust-metaprogramming)
  by [_Reintech_](https://reintech.io/)
- ["That's so Rusty: Metaprogramming"](https://dev.to/imaculate3/that-s-so-rusty-metaprogramming-49mj)
  by [_imaculate_](https://imaculate.github.io/)
- ["Metaprogramming with macros"](https://subscription.packtpub.com/book/web-development/9781800560819/2/ch02lvl1sec07/metaprogramming-with-macros)
  by [_packt_ publishing](https://packtpub.com)
- ["Rust Macros — Advanced Use Cases, Metaprogramming Mastery, and Code Generation"](https://medium.com/@alexandragrosu03/rust-macros-advanced-use-cases-metaprogramming-mastery-and-code-generation-6c8216af5086)
  by [_Alexandra Grosu_](https://medium.com/@alexandragrosu03)
- and so on...

Another approach I came across, in article
["Type-directed metaprogramming in Rust"](https://willcrichton.net/notes/type-directed-metaprogramming-in-rust/)
by [_Will Crichton_](https://willcrichton.net), is using rustc API (rust compiler)
directly in order to achieve similar goals as this post, but internal rustc API
is unstable which makes this approach both harder to implement and more time
consuming to maintain across versions.

- I find it to be a great introduction to rust internals, HIR and AST
  representations.
- It makes sense to go that route it if one is developing something akin to
  [`c2rust`](https://github.com/immunant/c2rust/).

In general, type metaprogramming and macros/preprocessors strive to achieve
similar goals but through different means. Type metaprogramming usually achieves
greater level of integration with the language type system, at the cost of being
somewhat harder to write and debug. Conversely, macros and preprocessors can
(optionally) provide much nicer error messages, are easier to reason about, but
are much more verbose to write and don't integrate into the build process quite
as nicely.

## Tuples As Type Lists

Lists are used to store varying number of **runtime values** of the same
compile-time type. Tuples are used to group _differently typed_ values with a
tradeoff of being fixed in size. Tuple size constraint as well as fixed typing
can't be circumvented, as that would void soundness of the type system (and it's
a compiler/implementation bug if achievable).

|  Type | Type Constraint | Size Constraint |
| ----: | :-------------: | :-------------: |
| Array |     Uniform     |  Compile-time   |
|  List |     Uniform     |     Runtime     |
| Tuple |     Varying     |  Compile-time   |

The fixed size is enforced directly by local type signatures, but it can also be
inferred in languages that support one of specialization, templatization or
generic types. In other words, we can use a variety of methods to evaluate final
type elements - so long as we keep in mind that they will have to be inferred by
the compiler at compile-time.

Rust doesn't have variable argument generics
([yet](https://github.com/rust-lang/rfcs/issues/376)) which is a well-trodden
path of implementing this sort of functionality, but it's got one of the best
macro systems which can be used instead.

In order to manipulate a type list or (more correctly) sequence, destructuring
into **head** and **tail** elements is a necessity.

In type theory, I believe these would be defined as:

$$
\mathrm{Tuple} : \Pi_{(A_0:\mathcal{U_i})}\Pi_{(A_1:\mathcal{U_{i+1}})}\dots\Pi_{(A_n:\mathcal{U_{i+n}})}(A_0,\ A_1,\ \dots,\ A_n)\\
\mathrm{TypeList} :\equiv \mathrm{Tuple}
$$

$$
\mathrm{head}: \mathrm{Tuple}(A_0,\ A_1,\ \dots,\ A_n) \to A_0\\
\mathrm{head}((a_0,\ a_1,\ \dots,\ a_n)) :\equiv a_0\\
$$

$$
\mathrm{tail}: \mathrm{Tuple}(A_0,\ A_1,\ \dots,\ A_n) \to \mathrm{Tuple}(A_1,\ A_2,\ \dots,\ A_n)\\
\mathrm{tail}((a_0,\ a_1,\ \dots,\ a_n)) :\equiv (a_1,\ a_2,\ \dots,\ a_n)\\
$$

<sub>Note that I'm not a mathematician, and am only including these definitions
for completeness sake. They're possibly non-compliant with Martin-Löf type
theory. I'm open to constructive input.</sub>

### Type Sequence Trait

It's a good idea to start by defining a trait that can be used to specify some
arbitrary type sequence. This will serve as an important stepping stone and make
out later implementation simpler. It's equivalent to above type theory
definition.

Due to lack of variable argument (vararg) generics, there must exist an upper
bound to supported sequence length, but thanks to macros we can make it
arbitrarily large. This is primarily a development inconvenience as vararg
generics end up producing the same executable code.

We declare our type sequence trait with previously mentioned fundamental
properties attached as we have limited use for an empty (marker) trait:

```rust
//#! file:"type_list.rs"
pub trait TypeList {
    type Head;
    type Tail: TypeList;
}

impl TypeList for () {
    type Head = (); // Should be ! type; once it's supported
    type Tail = ();
}
impl<A> TypeList for (A,) {
    type Head = A;
    type Tail = ();
}
impl<A, B> TypeList for (A, B) {
    type Head = A;
    type Tail = (B,);
}

// and so on...
```

Now after seeing the first few cases, it's clearer that `TypeList`
implementations can be generalized and then generated using macros:

```rust
//#! copy file:"type_list.rs"

pub trait TypeList {
    type Head;
    type Tail: TypeList;
}

macro_rules! impl_type_list {
    () => {
        impl TypeList for () {
            type Head = ();
            type Tail = ();
        }
    };
    ($A:ident) => {
        impl<$A> TypeList for ($A,) {
            type Head = $A;
            type Tail = ();
        }
    };
    ($A:ident, $($B:ident),*) => {
        impl<$A, $($B),*> TypeList for ($A, $($B),*) {
            type Head = $A;
            type Tail = ($($B,)*);
        }
    };
}

macro_rules! smaller_tuples_too {
    ($m: ident, $ty: ident) => {
        $m!{}
        $m!{$ty}
    };
    ($m: ident, $ty: ident, $($tt: ident),*) => {
        smaller_tuples_too!{$m, $($tt),*}
        $m!{$ty, $($tt),*}
    };
}

// short for calling smaller_tuples_too with 64 arguments
macro_rules! all_supported_tuples {
    ($m: ident) => {
        #[rustfmt::skip]
        smaller_tuples_too!($m,
            A, B, C, D, E, F, G, H, I, J,
            K, L, M, N, O, P, Q, R, S, T,
            U, V, W, X, Y, Z, AA, AB, AC, AD,
            AE, AF, AG, AH, AI, AJ, AK, AL, AM, AN,
            AO, AP, AQ, AR, AS, AT, AU, AV, AW, AX,
            AY, AZ, BA, BB, BC, BD, BE, BF, BG, BH,
            BI, BJ, BK, BL
        );
    };
}
```

Combining the above two macros allows us to generate 64 implementations of the
trait with a single macro call:

```rust
//#! copy file:"type_list.rs"
all_supported_tuples!(impl_type_list);
```

And just like that we've built a mechanism for forward iteration. You can give
it a spin in the
[playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=9bab9b8c8284f08f50a1d2269da203f6)
([gist](https://gist.github.com/rust-play/9bab9b8c8284f08f50a1d2269da203f6)).

It's already noticable how accessing the n-th element is inconvenient because we
need to cast the `Tail` type at each level. The casting is neccessary because
`Tail` could satisfy multiple different traits with identically named associated
type.<br/>
This pain point can be alleviated, but I'll address it in a later post as
operations covered in this post don't require indexing. I just wanted to
acknowledge and point it out it for now.

## Type Operations

In order to map types, we have to figure out how to express functions that
operate on _type values_. Compiled languages have a strict hierarchy of type
families which encode when the type/data is available and how much information
about it is available at each execution stage:

|                    Name |                   Description                    |                 Type                 |          Size           |
| ----------------------: | :----------------------------------------------: | :----------------------------------: | :---------------------: |
|                    Kind |         Structure information of a type          |                Syntax                |    Compiler internal    |
|                    Type |         Property information of a value          |    Inheritance and/or composition    |          Known          |
|                   Trait |               Behavior information               |    Inheritance and/or composition    |          None           |
|               Interface |              Structure information               |    Inheritance and/or composition    | Lower bound constraint  |
|    Partial Type (`dyn`) |     Partial information of value properties      | Partial (structure and/or interface) |         Unknown         |
|                Constant |      Immutable value known at compile time       |                Known                 |          Known          |
|                Variable |          Mutable value known at runtime          |                Known                 |          Known          |
|          Pointer (`*T`) | Pointer to location of (first) constant/variable |                Known                 | Known (if not sequence) |
| Address (`*u8`/`usize`) |   Memory address of (first) constant/variable    |                Erased                |         Unknown         |

In many cases the compiler handles conversion automatically - allowing a const
function call with runtime arguments. So in order for our types to stay in the
type space, all conversion must happen inside it. That's because constant
functions deal with discrete values and we want to manipulate types.

Rust allows handling of type projection via type aliases much as C++ does. In
Rust however, one relies on traits instead of classes for the same
functionality:

```rust
//#! name:"example"
trait TypeSpaceFunction<T> {
    // not yet valid syntax; see issue #29661
    type Value = (Transformed, T);
}
```

One notable difference is that in Rust, one can associate trait implementations
with some other data which simplifies how conditionals are handled:

```rust
//#! name:"example"
trait SplitFunction {
    type Value;
}
impl<T> SplitFunction for MyType<T> {
    type Value = T;
}
impl<T> SplitFunction for [T; N] {
    type Value = T;
}
```

In C++ template metaprogramming, ifs or filters have to be used in constant
expressions to achieve similar results.

## Generic Type Projection

With former utilities in mind we want to construct a way of mapping a type
sequence `(A, B, C)` into another, more complex, type sequence.

Usually, this can be done with a simple projection and it

Projection operation we're making a producer for consumes the discriminant $D$,
input reqirements $I_r$. It is applied to a tuple of discriminant $D$, input type
`I`, and output type `O`, and produces a type $Value :\equiv O$

The reason for using a _discriminant_ is that it allows better code reuse. A
minimal working version doesn't neccessarily need it, but the resulting code
would need to be specialized for each use case.

Our type function type looks like the following:

$$
TypeF: \Pi_{(d: D, i: I)} O(d,i)
$$

that is to say - it produces a type that depends on input types $d: D$ and $i: I$.

We want to get something like:

$$
B_i : O\\
RecursiveApplicator(T, F) := F(Head(T)), Tail(T)\\
TypeMapping: \Pi_{(d: D, A_i: I)} ( \to (B_0, B_1, \dots, B_n))
$$

$$
Apply: (TypeF, I) \to \Pi_{O: D} \Pi_{O: D} O\\
Method: Apply\\
TypeMapping: (Tuple, Method) -> \\
$$

### Apply Operator

We start with a simple application trait:

```rust
//#! copy file:"mapping.rs"
trait Apply {
    type Value;
}
```

and declare the application discriminant ("function name"):

```rust
//#! file:"model.rs"
struct ToInputConnector<Model> {
    _phantom: std::marker::PhantomData<Model>,
}
```

The discriminant type (`ToInputConnector`) will never be constructed. Using it
allows the same `Apply` trait to be used for multiple different mappings which
makes it more ergonomic to import `Apply` operation.

I'm using `Phantom` in `ToInputConnector` because Rust will require `Model` to
be used in the signature of `Apply` implementation. Generally, any types that
stay constant across all mapping invocations have to be placed into the
`Phantom` here.

Then _method_ application can be specified (think of it as the body of the method):

```rust
//#! file:"model.rs"
impl<Model, T> Apply for (ToInputConnector<Model>, T)
where
    Model: 'static,
    T: 'static,
{
    type Value = (&'static str, &'static dyn Handler<Model, T>);
}
```

You'll notice I'm implementing the method for a tuple of method and arguments
(in this case a single one), that's because there's no other way of passing
compile time information into `Apply`:

- If we tried storing `T` as a generic on `Apply`, we wouldn't be able to invoke
  it for different types within the same type list.
- Conversly, if we tried storing it on `ToInputConnector`, then our mapping
  wouldn't be agnostic with respect to method it's applying.

To summarize, **variable types** are stored in the tuple we're calling `Apply`
on and **non-variable types** (such as `Model` in the example case) should go
into the implementation discriminant struct (`ToInputConnector`).

Note that multiple variable arguments will change how you implement
`TypeMapping` in the following section.

### Apply-to-all

Now that _application_ part of mapping is done with, all that's left is coupling
together all the operations to _apply_ the mapping _for every type_ in the list
_and return_ a new list with mapping results.

Sadly, this is a place multiple implementations are necessary again (for each
tuple size). As always, macros come to the rescue:

```rust
//#! copy file:"mapping.rs"
pub trait TypeMapping<Method> {
    type Value;
}

macro_rules! impl_mapping {
    () => {
        impl<Method> TypeMapping<Method> for ()
        {
            type Value = ();
        }
    };
    ($($A: ident),+) => {
        impl<Method, $($A),+> TypeMapping<Method> for ($($A,)+)
        where
            $((Method, $A): Apply),+
        {
            type Value = (
                $(<(Method, $A) as Apply>::Value,)+
            );
        }
    };
}

all_supported_tuples!(impl_mapping);
```

`TypeMapping` implementations here will change somewhat if multiple variable
types or lifetimes are needed.

You can try out a simplified version without the constant `M` type (for model)
on the
[playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=10f15816801e32933ed6777c02da93d2)([gist](https://gist.github.com/rust-play/10f15816801e32933ed6777c02da93d2)).

While writing this article, I also noticed that mapping with lifetimes doesn't
seem to work, so I removed the system lifetime from `ToInputConnector`
signature. Compiler seems to fail at normalizing associated types on a trait
that is implemented for struct with a lifetime ([minimal
reproduction](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=b539abe29f693183c9b785c6f904f508);
[rustc issue](https://github.com/rust-lang/rust/issues/106569)). For future
reference (once the issue get fixed), lifetimes go on the discriminant struct if
they don't change for mapping applications, or alternatively, get paired with
types in tuples the `TypeMapping` is implemented for if they do change.

## Profit

Our new `Model` trait and implementation for `Player` looks as following:

```rust
//#! file:"model.rs"
struct ToInputConnector<Model> {
    _phantom: std::marker::PhantomData<Model>,
}
impl<M, T> Apply for (ToInputConnector<M>, T)
where
    M: 'static,
    T: 'static,
{
    type Value = (&'static str, &'static dyn Handler<M, T>);
}
struct ToOutputConnector;
impl<T> Apply for (ToOutputConnector, T)
    T: 'static,
{
    type Value = &'static str;
}

trait Model<'s, I: TypeList, O: TypeList>: Sized {
    fn input_connectors(&self) -> <I as TypeMapping<ToInputConnector<Self>>>::Value
    where
        I: TypeMapping<ToInputConnector<Self>>;

    fn output_connectors(&self) -> <O as TypeMapping<ToOutputConnector>>::Value
    where
        O: TypeMapping<ToOutputConnector>;

    // other functions...
}

struct Ball;
struct Player;

impl<'s> Model<'s, (Ball,), (Ball,)> for Player {
    fn input_connectors(&self) -> <(Ball,) as TypeMapping<ToInputConnector<Self>>>::Value
    where
        (Ball,): TypeMapping<ToInputConnector<Self>>,
    {
        (("recieve", handle_ball),)
    }
    fn output_connectors(&self) -> <(Ball,) as TypeMapping<ToOutputConnector>>::Value
    where
        (Ball,): TypeMapping<ToOutputConnector>,
    {
        ("send",)
    }
}

fn handle_ball(_model: &mut Player, _event: Ball) -> Result<(), String> {
    Ok(())
}
```

With that, connectors are done. I want to point out that the implementation
above (somewhat) successfully replaces a whole bunch of complicated code that
was previously generated by `#[litesim_model]`:

```rust
//#! file:"model.rs"
impl<'s> Model<'s> for Player {
    fn input_connectors(&self) -> Vec<&'static str> {
        vec!["receive"]
    }
    fn get_input_handler<'h>(&self, index: usize) -> Option<Box<dyn ErasedHandler<'h, 's>>>
    where
        's: 'h,
    {
        match index {
            0usize => {
                let handler: Box<&dyn Handler<&mut Player, Event<()>) -> Result<(), SimulationError>> = Box::new(
                    &(|_: &mut Player, _: Event<()>| {
                        // details...
                    }),
                );
                return Some(handler);
            }
            _ => return None,
        }
    }
    fn output_connectors(&self) -> Vec<OutputConnectorInfo> {
        vec![
            OutputConnectorInfo::new::<()>("send"),
        ]
    }
    // other functions...
}
```

Notably:

- I got rid of type erasure for `Handler`.
  - Now the `Model` will have to be type-erased in order for us to store it in a
    `Vec`. That's however much safer and I can now hide a whole bunch of
    implementation details from end-users (i.e. `ErasedHandler`,
    `OutputConnectorInfo`).
- Type signature dictates the number of connector labels and handlers, which
  prevents invalid use.
  - Previously, the library would internally panic with somewhat obscure stack
    traces which made it hard for end-users to realize they're violating API
    requirements.
- Accessing a handler function and connector names is now a `O(1)` operation
  instead of `O(n)`.
  - As the compiler knows where are handlers are, it can go crazy with
    optimizations.
  - `O(n)` doesn't capture the fact that there could've been _a lot_ of jumps on
    simulation hot path.
  - It's only `O(1)` within the same model though, the simulation will still
    have to access this data dynamically.

In the process, I also lost the ability to change the number of inputs and
outputs at runtime, but that part of functionality required a rework anyway as
it wasn't completely sound. I was forced to use `Vec` with dynamic type checking
without code introduced in this article. The original plan was defining a
separate `DynamicModel` trait so that `litesim` can avoid runtime type checking
for models with static interfaces.

We'll deal with the consumption of generated type signatures in a later post, as
well as going over how we can write a getter for our type lists and bridge
indices from runtime to compile time.
